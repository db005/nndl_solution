2-1 分析为什么平方损失函数不适用于分类问题？

分类问题中的标签，是没有连续的概念的。每个标签之间的距离也是没有实际意义的，所以预测值和标签两个向量之间的平方差这个值不能反应分类这个问题的优化程度。
比如分类 1,2,3, 真实分类是1, 而被分类到2和3错误程度应该是一样的, 但是平方损失函数的损失却不相同。

2-2 在线性回归中，如果我们给每个样本$\(x^{(n)},y^{(n)})$赋予一个权重$r^{(n)}$，经验风险函数为
$$R(w)=\frac{1}{2}\sum_{n=1}^{N}r^{(n)}(y^{(n)}-w^Tx^{(n)})^2$$
计算其最优参数$w^*$，并分析权重$r^{(n)}$.

令 $R=diag(r^{(n)})$。
$$\frac{\partial}{\partial w}R(w)=\frac{1}{2}\frac{\partial R || y-X^Tw ||^2}{\partial w}$$
$$-XR(y-X^Tw)=0$$
$$w^*=(XRX^T)^{-1}XRy$$

2-3 证明在线性回归中，如果样本数量$𝑁$小于特征数量$𝐷+1$，则$XX^T$的秩最大为$𝑁$．

样本数量小于特征数量，则$X$的秩最大为$N$。根据定理
$$Rank(AB) \leq min{Rank(A),Rank(B)}$$
因此，$XX^T$的秩最大为$N$.

2-4 在线性回归中，验证岭回归的解为结构风险最小化准则下的最小二乘法估计，见公式(2.44)．

岭回归的解$𝒘^∗$ 可以看作结构风险最小化准则下的最小二乘法估计，其目标函数可以写为
$$R(w)=\frac{1}{2}||y-X^Tw||^2+\frac{1}{2}\lambda||w||^2$$

岭回归的解如下：
$$w^*=(XX^T+\lambda I)^{-1}Xy$$

接下来求解次目标函数的最优解，看他是否与岭回归的解一致

$$\frac{\partial R(w)}{\partial w}=0$$

$$-X(y-X^Tw)+\lambda w=0$$

$$-Xy+XX^Tw+\lambda w=0$$

$$(XX^T+\lambda)w=Xy$$

$$w^*=(XX^T+\lambda)^{-1}Xy$$

2-5 在线性回归中，若假设标签$𝑦 ∼ 𝒩(𝒘^T𝒙, 𝛽)$，并用最大似然估计来优化参数，验证最优参数为公式(2.52)的解．

设样本特征向量集为${x^{(1)},x^{(2)},...,x^{(n)}}$，对应的标签集为${y^{(1)},y^{(2)},...,y^{(n)}}$，令$X={x^{(1)},x^{(2)},...,x^{(n)}}$
